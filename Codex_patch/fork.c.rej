--- kernel/fork.c
+++ kernel/fork.c
@@ -63,6 +63,24 @@
 #include <linux/fs_struct.h>
 #include <trace/sched.h>
 #include <linux/magic.h>
+#ifdef CONFIG_KRG_KDDM
+#include <kddm/kddm_info.h>
+#endif
+#ifdef CONFIG_KRG_HOTPLUG
+#include <kerrighed/namespace.h>
+#endif
+#ifdef CONFIG_KRG_PROC
+#include <kerrighed/task.h>
+#include <kerrighed/krginit.h>
+#endif
+#ifdef CONFIG_KRG_EPM
+#include <kerrighed/signal.h>
+#include <kerrighed/children.h>
+#include <kerrighed/application.h>
+#endif
+#ifdef CONFIG_KRG_SCHED
+#include <kerrighed/scheduler/info.h>
+#endif
 
 #include <asm/pgtable.h>
 #include <asm/pgalloc.h>
@@ -99,7 +117,10 @@
 #ifndef __HAVE_ARCH_TASK_STRUCT_ALLOCATOR
 # define alloc_task_struct()	kmem_cache_alloc(task_struct_cachep, GFP_KERNEL)
 # define free_task_struct(tsk)	kmem_cache_free(task_struct_cachep, (tsk))
-static struct kmem_cache *task_struct_cachep;
+#ifndef CONFIG_KRG_EPM
+static
+#endif
+struct kmem_cache *task_struct_cachep;
 #endif
 
 #ifndef __HAVE_ARCH_THREAD_INFO_ALLOCATOR
@@ -540,6 +606,9 @@
 			spin_unlock(&mmlist_lock);
 		}
 		put_swap_token(mm);
+#ifdef CONFIG_KRG_EPM
+		BUG_ON(atomic_read(&mm->mm_ltasks) != 0);
+#endif
 		mmdrop(mm);
 	}
 }
@@ -600,10 +669,19 @@
 
 	/* Get rid of any cached register state */
 	deactivate_mm(tsk, mm);
+#ifdef CONFIG_KRG_EPM
+	if (mm)
+		atomic_dec(&mm->mm_ltasks);
+#endif
 
 	/* notify parent sleeping on vfork() */
 	if (vfork_done) {
 		tsk->vfork_done = NULL;
+#ifdef CONFIG_KRG_EPM
+		if (tsk->remote_vfork_done)
+			krg_vfork_done(vfork_done);
+		else
+#endif
 		complete(vfork_done);
 	}
 
@@ -668,6 +746,9 @@
 	return mm;
 
 free_pt:
+#ifdef CONFIG_KRG_EPM
+	atomic_dec(&mm->mm_ltasks);
+#endif
 	mmput(mm);
 
 fail_nomem:
@@ -909,9 +1038,31 @@
 {
 	struct signal_struct *sig;
 
+#ifdef CONFIG_KRG_EPM
+	if (krg_current && !in_krg_do_fork()) {
+		/*
+		 * This is a process migration or restart: signal_struct is
+		 * already setup.
+		 */
+		tsk->signal->curr_target = tsk;
+		return 0;
+	}
+
+	if (!krg_current)
+#endif
 	if (clone_flags & CLONE_THREAD) {
+#ifdef CONFIG_KRG_EPM
+		if (current->signal->kddm_obj)
+			krg_signal_writelock(current->signal);
+#endif
 		atomic_inc(&current->signal->count);
 		atomic_inc(&current->signal->live);
+#ifdef CONFIG_KRG_EPM
+		if (current->signal->kddm_obj) {
+			krg_signal_share(current->signal);
+			krg_signal_unlock(current->signal);
+		}
+#endif
 		return 0;
 	}
 
@@ -988,11 +1153,20 @@
 static void cleanup_signal(struct task_struct *tsk)
 {
 	struct signal_struct *sig = tsk->signal;
+#ifdef CONFIG_KRG_EPM
+	struct signal_struct *locked_sig;
+#endif
 
+#ifdef CONFIG_KRG_EPM
+	locked_sig = krg_signal_exit(sig);
+#endif
 	atomic_dec(&sig->live);
 
 	if (atomic_dec_and_test(&sig->count))
 		__cleanup_signal(sig);
+#ifdef CONFIG_KRG_EPM
+	krg_signal_unlock(locked_sig);
+#endif
 }
 
 static void copy_flags(unsigned long clone_flags, struct task_struct *p)
@@ -1149,6 +1341,9 @@
 	p->rcu_read_lock_nesting = 0;
 	p->rcu_flipctr_idx = 0;
 #endif /* #ifdef CONFIG_PREEMPT_RCU */
+#ifdef CONFIG_KRG_EPM
+	if (!krg_current)
+#endif
 	p->vfork_done = NULL;
 	spin_lock_init(&p->alloc_lock);
 
@@ -1226,8 +1427,23 @@
 	/* Perform scheduler related setup. Assign this task to a CPU. */
 	sched_fork(p, clone_flags);
 
+#ifdef CONFIG_KRG_CAP
+	krg_cap_fork(p, clone_flags);
+#endif /* CONFIG_KRG_CAP */
+
+#ifdef CONFIG_KRG_KDDM
+	if (!kh_copy_kddm_info)
+		p->kddm_info = NULL;
+	else if ((retval = kh_copy_kddm_info(clone_flags, p)))
+		goto bad_fork_cleanup_policy;
+#endif /* CONFIG_KRG_KDDM */
+
 	if ((retval = audit_alloc(p)))
+#ifdef CONFIG_KRG_KDDM
+		goto bad_fork_cleanup_kddm_info;
+#else
 		goto bad_fork_cleanup_policy;
+#endif /* CONFIG_KRG_KDDM */
 	/* copy all the process information */
 	if ((retval = copy_semundo(clone_flags, p)))
 		goto bad_fork_cleanup_audit;
@@ -1426,20 +1708,51 @@
 	 * thread can't slip out of an OOM kill (or normal SIGKILL).
  	 */
 	recalc_sigpending();
+#ifdef CONFIG_KRG_EPM
+	/* Only check if inside a remote clone() */
+	if (!krg_current || in_krg_do_fork())
+#endif
 	if (signal_pending(current)) {
 		spin_unlock(&current->sighand->siglock);
 		write_unlock_irq(&tasklist_lock);
 		retval = -ERESTARTNOINTR;
+#if defined(CONFIG_KRG_SCHED)
+		goto bad_fork_free_krg_sched;
+#elif defined(CONFIG_KRG_PROC)
+		goto bad_fork_free_krg_task;
+#else
 		goto bad_fork_free_graph;
+#endif
 	}
 
+#ifdef CONFIG_KRG_EPM
+	retval = krg_children_fork(p, pid, clone_flags);
+	if (retval) {
+		spin_unlock(&current->sighand->siglock);
+		write_unlock_irq(&tasklist_lock);
+#ifdef CONFIG_KRG_SCHED
+		goto bad_fork_free_krg_sched;
+#else
+		goto bad_fork_free_krg_task;
+#endif
+	}
+#endif /* CONFIG_KRG_EPM */
+#ifdef CONFIG_KRG_EPM
+	if (!krg_current || !thread_group_leader(krg_current))
+#endif
 	if (clone_flags & CLONE_THREAD) {
 		p->group_leader = current->group_leader;
 		list_add_tail_rcu(&p->thread_group, &p->group_leader->thread_group);
 	}
 
 	if (likely(p->pid)) {
+#ifdef CONFIG_KRG_EPM
+		if (p->real_parent != baby_sitter)
+#endif
 		list_add_tail(&p->sibling, &p->real_parent->children);
+#ifdef CONFIG_KRG_EPM
+		attach_pid(p, PIDTYPE_PID, pid);
+#endif
 		tracehook_finish_clone(p, clone_flags, trace);
 
 		if (thread_group_leader(p)) {
@@ -1454,20 +1767,52 @@
 			list_add_tail_rcu(&p->tasks, &init_task.tasks);
 			__get_cpu_var(process_counts)++;
 		}
+#ifndef CONFIG_KRG_EPM
 		attach_pid(p, PIDTYPE_PID, pid);
+#endif
 		nr_threads++;
 	}
+#ifdef CONFIG_KRG_PROC
+	krg_task_fill(p, clone_flags);
+#endif
 
 	total_forks++;
 	spin_unlock(&current->sighand->siglock);
 	write_unlock_irq(&tasklist_lock);
+#ifdef CONFIG_KRG_PROC
+	krg_task_commit(p);
+#endif
+#ifdef CONFIG_KRG_EPM
+	krg_children_commit_fork(p);
+#endif
 	proc_fork_connector(p);
 	cgroup_post_fork(p);
+#ifdef CONFIG_KRG_HOTPLUG
+	current->create_krg_ns = saved_create_krg_ns;
+#endif
 	return p;
 
+#ifdef CONFIG_KRG_SCHED
+bad_fork_free_krg_sched:
+	krg_sched_info_free(p);
+#endif
+#ifdef CONFIG_KRG_PROC
+bad_fork_free_krg_task:
+	krg_task_abort(p);
+#endif
+#ifdef CONFIG_KRG_EPM
+bad_fork_cleanup_children:
+	krg_children_abort_fork(p);
+bad_fork_cleanup_application:
+	if (!krg_current)
+		krg_exit_application(p);
+#endif
 bad_fork_free_graph:
 	ftrace_graph_exit_task(p);
 bad_fork_free_pid:
+#ifdef CONFIG_KRG_EPM
+	if (!krg_current)
+#endif
 	if (pid != &init_struct_pid)
 		free_pid(pid);
 bad_fork_cleanup_io:
@@ -1475,12 +1820,31 @@
 bad_fork_cleanup_namespaces:
 	exit_task_namespaces(p);
 bad_fork_cleanup_mm:
+#ifdef CONFIG_KRG_MM
+	if (p->mm && p->mm->mm_id && (clone_flags & CLONE_VM))
+#ifdef CONFIG_KRG_EPM
+		if (!krg_current)
+#endif
+			KRGFCT(kh_mm_release)(p->mm, 1);
+#endif
+#ifdef CONFIG_KRG_EPM
+	if (p->mm)
+		atomic_dec(&p->mm->mm_ltasks);
+#endif
 	if (p->mm)
 		mmput(p->mm);
 bad_fork_cleanup_signal:
+#ifdef CONFIG_KRG_EPM
+	if (!krg_current || in_krg_do_fork())
+#endif
 	cleanup_signal(p);
 bad_fork_cleanup_sighand:
+#ifdef CONFIG_KRG_EPM
+	if (!krg_current || in_krg_do_fork())
+		krg_sighand_cleanup(p->sighand);
+#else
 	__cleanup_sighand(p->sighand);
+#endif /* CONFIG_KRG_EPM */
 bad_fork_cleanup_fs:
 	exit_fs(p); /* blocking */
 bad_fork_cleanup_files:
@@ -1489,12 +1853,20 @@
 	exit_sem(p);
 bad_fork_cleanup_audit:
 	audit_free(p);
+#ifdef CONFIG_KRG_KDDM
+bad_fork_cleanup_kddm_info:
+	if (p->kddm_info)
+		kmem_cache_free(kddm_info_cachep, p->kddm_info);
+#endif
 bad_fork_cleanup_policy:
 #ifdef CONFIG_NUMA
 	mpol_put(p->mempolicy);
 bad_fork_cleanup_cgroup:
 #endif
 	cgroup_exit(p, cgroup_callbacks_done);
+#ifdef CONFIG_KRG_EPM
+	if (!krg_current)
+#endif
 	delayacct_tsk_free(p);
 	if (p->binfmt)
 		module_put(p->binfmt->module);
@@ -1507,6 +1879,9 @@
 bad_fork_free:
 	free_task(p);
 fork_out:
+#ifdef CONFIG_KRG_HOTPLUG
+	current->create_krg_ns = saved_create_krg_ns;
+#endif
 	return ERR_PTR(retval);
 }
 
@@ -1825,9 +2220,16 @@
 	struct files_struct *fd, *new_fd = NULL;
 	struct nsproxy *new_nsproxy = NULL;
 	int do_sysvsem = 0;
+#ifdef CONFIG_KRG_HOTPLUG
+	int saved_create_krg_ns;
+#endif
 
 	check_unshare_flags(&unshare_flags);
 
+#ifdef CONFIG_KRG_HOTPLUG
+	saved_create_krg_ns = current->create_krg_ns;
+	current->create_krg_ns = 0;
+#endif
 	/* Return -EINVAL for all unsupported flags */
 	err = -EINVAL;
 	if (unshare_flags & ~(CLONE_THREAD|CLONE_FS|CLONE_NEWNS|CLONE_SIGHAND|
